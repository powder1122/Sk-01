{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f1c0e76",
   "metadata": {},
   "source": [
    "# 6월 20일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b881c805",
   "metadata": {},
   "source": [
    "- 머신러닝 --> **데이터가 중요!!** \n",
    "- **컴퓨터**가 **스스로** 학습하여 패턴을 발견\n",
    "- 패턴을 발견하기 위한 학습 방법을 만들고 나누어 분 것이 머신러닝\n",
    "- 머신러닝은 또 다시 지도학습과 비지도학습으로 분류\n",
    "- +강화 학습이 존재. 답을 잘 맞추도록 유도하는 방법\n",
    "- 머신러닝에서 더 나아가 딥러닝(인공신경망 모델) 생성\n",
    "\n",
    "- **패턴을 찾으면 예측, 또는 분류가 가능해지고, 이 데이터를 통해 의사결정을 내릴 수 있게 된다.**\n",
    "\n",
    "- 범주형 데이터 --> 전처리. 숫자 형식으로 바꾸는 작업 필요.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa97851",
   "metadata": {},
   "source": [
    "# 지도학습 - 분류 알고리즘\n",
    "- 분류 문제의 개념\n",
    "- 로지스틱 회귀의 이해\n",
    "- 성능 평가 지표(정확도, Precision, Recall, F1-Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22419bdd",
   "metadata": {},
   "source": [
    "## 분류 문제의 개념\n",
    "- 분류: \n",
    "    - 주어진 데이터를 특정 범주나 클래스로 분류하는 작업\n",
    "    - 지도 학습의 한 유형 --> 데이터에 레이블(정답)이 존재\n",
    "    - 모델은 이 레이블을 학습하여 새로운 데이터가 주어졌을 때 올바른 클래스를 예측하도록 훈련됨\n",
    "\n",
    "- 분류의 주요 목표\n",
    "    - 정확한 예측: 데이터가 어떤 클래스에 속하는지 최대한 정확히 예측\n",
    "    - 실용적 적용: 실제 문제에서 유용한 정보를 제공\n",
    "        - 예: 스팸 필터링 모델은 높은 정확도와 낮은 오탐을 목표로 함\n",
    "\n",
    "- 분류 문제의 특징\n",
    "    - 입력 데이터: 다양한 특징을 가진 데이터\n",
    "    - 출력 데이터: 데이터가 속한 범주 또는 클래스\n",
    "    - 클래스 개수\n",
    "        - 이진 분류: 두 개의 클래스만 예측(True/False, 0/1)\n",
    "        - 다중 클래스 분류: 세 개 이상의 클래스 예측(예: 고양이, 강아지, 새)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24175b1b",
   "metadata": {},
   "source": [
    "- 분류의 작동 방식\n",
    "    1. 데이터 수집 및 전처리: 데이터를 수집하고, 결측값 처리, 스케일링, 정규화 등을 통해 준비. **(데이터 분류 필수!!)**\n",
    "\n",
    "    2. 모델 학습: 입력 데이터(특징, Feature)와 레이블(정답, Labels)을 활용해 모델을 학습시킴.\n",
    "\n",
    "    3. 모델 예측: 새로운 데이터가 들어오면 학습한 모델이 예측 값을 출력.\n",
    "\n",
    "    4. 평가: 모델의 예측 결과를 평가하여 성능 지표로 측정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d38f7e5",
   "metadata": {},
   "source": [
    "## 로지스틱 회귀의 이해\n",
    "### 로지스틱 회귀\n",
    "- 분류 문제를 해결하기 위한 지도 학습 알고리즘\n",
    "\n",
    "- 이름에 회귀가 포함되어 있지만, 실제로는 연속적인 값을 예측하는 것이 아니라 데이터를 \n",
    "**클래스**로 분류하는 데 사용\n",
    "\n",
    "- 로지스틱 회귀는 이진 분류 문제에서 가장 널리 사용되는 기법 중 하나\n",
    "\n",
    "- 데이터를 분석하고 특정 데이터가 특정 클래스에 속할 확률을 예측\n",
    "    - 예: 로지스틱 회귀는 \"이 이메일이 스팸일 확률이 85%\"와 같은 값을 출력하며, 이 확률에 따라 특정 클래스에 할당"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b293a3f",
   "metadata": {},
   "source": [
    "### 로지스틱 회귀의 작동 원리\n",
    "1. 선형 회귀의 확장\n",
    "    - 로지스틱 회귀는 먼저 선형 회귀처럼 데이터를 학습\n",
    "    - 선형 회귀의 예측 값(연속 값)을 분류 문제에 적합하도록 변환\n",
    "    - 문제: 선형회귀는 0에서 1사이의 확률 값을 보장하지 않음\n",
    "\n",
    "2. 시그모이드 함수 적용\n",
    "    - 로지스틱 회귀는 예측 값 z를 시그모이드 함수를 사용해 0과 1 사이의 값(확률)로 변환. (시그모이드 함수의 출력 값은 항상 0 <= 𝜎(𝑧) <= 1>)\n",
    "\n",
    "3. 클래스 결정\n",
    "    - 시그모이드 함수의 결과(확률 값)가 0.5 이상이면 1, 그렇지 않으면 0으로 분류 --> 임계값 변경 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a90dd3",
   "metadata": {},
   "source": [
    "### 로지스틱 회귀의 과정\n",
    "1. 가설 설정\n",
    "    - 입력 받은 데이터의 특징을 선형 결합하여 z를 계산하고, 이를 시그모이드 함수에 통과시켜 확률을 계산\n",
    "    - 모델 출력 ℎ𝜃(𝑥)=𝜎(z)\n",
    "\n",
    "2. 손실 함수 정의\n",
    "    - 로지스틱 회귀는 로그 손실 함수를 사용(Log Loss)\n",
    "\n",
    "3. 모델 학습\n",
    "    - 경사하강법을 사용하여 가중치와 절편 값을 업데이트\n",
    "    - 모델이 점점 더 정확하게 데이터를 분류하도록 학습\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2301c9b",
   "metadata": {},
   "source": [
    "## 성능 평가 지표 (정확도, Precision, Recall, F1-Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772184f9",
   "metadata": {},
   "source": [
    "### 성능 평가 지표\n",
    "- 분류 모델의 성능을 평가하기 위해 다양한 평가 지표가 사용\n",
    "- 각각의 지표는 모델의 성능을 다양한 관점에서 분석하며, 특정 문제에 더 적합한 지표를 선택 해야함\n",
    "\n",
    "- 혼동 행렬(Confusion Matrix)\n",
    "    - 모든 평가 지표는 혼동 행렬을 기반으로 계산\n",
    "\n",
    "- 지표 종류\n",
    "    - 정확도\n",
    "    - 정밀도\n",
    "    - 재현율\n",
    "    - F1-Score\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debae0d0",
   "metadata": {},
   "source": [
    "- 지표 선택 기준\n",
    "    - 정확도: 클래스가 균형 잡혀 있을 때 적합\n",
    "        - 예: 시험 점수 채점 모델\n",
    "\n",
    "    - 정밀도: False Positive가 중요한 경우\n",
    "        - 예: 스팸 이메일 분류(정상 이메일이 스팸으로 분류되면 안 됨)\n",
    "    \n",
    "    - 재현율: False Negative가 중요한 경우\n",
    "        - 예: 암 진단(암 환자를 놓치는 일이 없어야 함)\n",
    "    \n",
    "    - F1-Score: 정밀도와 재현율의 균형이 중요할 때\n",
    "        - 예: 자연어 처리에서 키워드 추출\n",
    "\n",
    "\n",
    "- 보안의 경우 공격인데 공격이 아니라고 판단하는 경우 (False Negative)를 최대한 줄여야 한다!\n",
    "- 지표를 보고 개선할 부분을 찾는 등 전략적인 사용!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd09d12",
   "metadata": {},
   "source": [
    "# 모델 성능 향상 - K-최근접 이웃(KNN)\n",
    "- KNN 알고리즘의 이해\n",
    "- K값의 선택과 영향\n",
    "- 모델의 성능 향상 및 하이퍼파라미터 튜닝\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44317b3",
   "metadata": {},
   "source": [
    "## KNN 알고리즘의 이해\n",
    "### KNN알고리즘\n",
    "- KNN은 지도 학습 알고리즘 중 하나\n",
    "- KNN의 핵심 아이디어는 **가까운 데이터가 비슷한 특성을 가진다**는 가정\n",
    "    - 새로운 데이터 포인트가 주어졌을 때, 이를 가장 가까운 데이터 포인트들의 그룹으로 분류하거나 값을 예측하는 데 사용(주로 분류에 사용)\n",
    "    \n",
    "    - 거리 기반!!\n",
    "\n",
    "- KNN을 언제 사용 하면 좋을까?\n",
    "    - 데이터의 패턴이 비선형적이고 복잡할 때 KNN이 좋은 성능을 보일 수 있다.\n",
    "    - 단, 데이터가 많거나 고차원일 경우 성능 저하를 겪을 수 있으므로 이런 경우 차원 축소나 데이터 전처리가 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599332eb",
   "metadata": {},
   "source": [
    "### KNN 작동 원리\n",
    "1. 훈련 데이터 준비\n",
    "    - 데이터가 여러 개의 특성으로 구성되어 있다고 가정\n",
    "    - 각각의 데이터는 특정 레이블 또는 값을 가지고 있음\n",
    "\n",
    "2. 거리 계산\n",
    "    - 새로운 데이터 포인트(예측하려는 데이터)와 훈련 데이터 사이의 거리를 계산 --> 가장 흔히 사용하는 거리는 **유클리드 거리**\n",
    "\n",
    "3. K개의 이웃 선택\n",
    "    - 가장 가까운 K개의 데이터 포인트를 선택\n",
    "    - K는 미리 정해진 하이퍼파라미터로, K의 값에 따라 모델의 성능이 달라짐(데이터가 크지 않을 시 숫자를 통해 사용할 수도 있다.)\n",
    "\n",
    "4. 결과 결정\n",
    "    - **분류**\n",
    "        - 선택된 K개의 이웃 중 가장 많은 빈도로 나타나는 레이블을 선택 --> 이를 다수결(Majirity Voting)이라고 함\n",
    "\n",
    "    - 회귀\n",
    "        - 선택된 K개의 이웃의 값을 평균을 내어 예측 값을 결정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2548494f",
   "metadata": {},
   "source": [
    "### KNN의 주요 특징\n",
    "- **모델 학습이 필요하지 않음**\n",
    "    - KNN은 훈련 과정에서 데이터를 저장하기만 하고, 새로운 데이터가 들어올 때 실시간으로 계산\n",
    "    - 이 때문에 Lazy Learning(게으른 학습)알고리즘이라고도 함\n",
    "\n",
    "- 단순성\n",
    "    - 복잡한 수학적 계산 없이 데이터 간 거리를 비교하여 예측을 수행하므로 이해하고 구현하기 쉬움\n",
    "\n",
    "- 다양한 응용\n",
    "    - 분류와 회귀 문제 모두에 사용할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434120f6",
   "metadata": {},
   "source": [
    "### K 값의 선택과 영향\n",
    "- KNN 알고리즘에서 𝐾 값은 매우 중요한 하이퍼파라미터\n",
    "    - 𝐾 는 모델이 예측을 할 때 고려하는 가장 가까운 이웃의 수를 의미\n",
    "    - 𝐾 값의 선택은 모델의 성능에 큰 영향을 미침\n",
    "    - 𝐾 는 새로운 데이터 포인트가 주어졌을 때, 이 데이터와 가장 가까운 𝐾개의 데이터 포인트를 기반으로 예측을 수행\n",
    "        - 예:\n",
    "            - 𝐾=1: 가장 가까운 하나의 이웃만 보고 결정.\n",
    "            - 𝐾=3: 가장 가까운 3개의 이웃을 보고 다수결로 결정.\n",
    "\n",
    "- K 값이 작을 때의 영향\n",
    "    - 장점\n",
    "        - 모델이 데이터의 세부적인 패턴을 잘 잡아냄\n",
    "        - 국소적 특징에 민감하므로 복잡 한 데이터를 처리하는 데 적합\n",
    "\n",
    "    - 단점\n",
    "        - 과적합 위험이 증가\n",
    "        - 노이즈에 의해 결과가 영향을 받을 가능성이 큼\n",
    "        - 작은 데이터 변화에도 모델의 결과가 달라질 수 있음\n",
    "\n",
    "- K 값 선택 시 고려 사항\n",
    "    - **데이터 크기**\n",
    "        - 작은 데이터셋: K값을 **작게 설정**하는 것이 적합. 예: 데이터가 50개라면 K = 3 or 5\n",
    "        - 큰 데이터셋: K 값을 **더 크게 설정**해도 됨. 예: 데이터가 수천 개라면 K = 15 or 20\n",
    "\n",
    "    - **홀수 값의 선택**\n",
    "        - **K는 보통 홀수로 설정하는 것이 좋다!!**: 동률을 방지하기 위함\n",
    "        - 클래스가 2개일 때 K가 짝수라면 결과가 모호해질 수 있음\n",
    "    \n",
    "    - **성능 평가를 위한 테스트 교차 검증**\n",
    "        - 다양한 K값을 시도하면서 모델 성능(정확도)을 비교하여 최적의 K값을 선택\n",
    "        - 과적합과 과소적합 사이에서 적절한 균형을 찾을 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542693a1",
   "metadata": {},
   "source": [
    "### 모델의 성능 향상 및 하이퍼 파라미터 튜닝\n",
    "- KNN 알고리즘의 성능은 다양한 요소에 의해 영향을 받는다!\n",
    "    - 성능을 최적화화려면 데이터 전처리, 거리 계산 방식, 그리고 하이퍼파라미터(특히 K값과 거리 계산 방식)를 신중히 조정해야 함\n",
    "\n",
    "- 모델 성능 향상 방법\n",
    "    - 데이터 전처리: **스케일링**, **이상치 제거**, 특성 선택\n",
    "    - **거리 계산 방식**: **유클리드, 맨해튼, 민코프스키** 등을 데이터 특성에 맞게 선택\n",
    "    - 하이퍼파라미터 튜닝: **최적의 K값을 교차 검증으로 선택.** 가중치를 부여하여 더 나은 성능 도출"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

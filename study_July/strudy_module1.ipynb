{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e4a622a",
   "metadata": {},
   "source": [
    "# 7월 2일 ~ 7월 7일 모듈 프로젝트 1\n",
    "- AI를 활용한 레시피 추천 프로그램\n",
    "\n",
    "## 구현한 기능(맡은 역할)\n",
    "- YOLO 모델과 openai를 사용한 이미지 기반 재료 추출\n",
    "- 학습한 데이터셋: roboflow (https://universe.roboflow.com/yolov5-rznzw/food-ingredients-7txer)\n",
    "\n",
    "### 모델 선정 이유\n",
    "- YOLO(You Only Look Once)는 CNN 기반의 객체 탐지 모델이지만, 단순 이미지 분류에 그치지 않고 이미지 내의 객체 위치와 클래스까지 동시에 탐지할 수 있는 구조를 가지고 있다. 기존의 CNN은 전체 이미지를 하나의 클래스로 분류하지만 YOLO는 다중 객체를 빠르고 정확하게 검출할 수 있어 복잡한 식재료 이미지에 적합하다고 생각했다. Faster R-CNN처럼 다중 객체 탐지가 가능한 모델도 있지만, YOLO는 상대적으로 속도가 빠르고 구현이 간단하기 때문에 선택하게 되었다.\n",
    "\n",
    "\n",
    "### 기본 구조\n",
    "- 이미지 처리 방식: 입력받은 이미지 수 만큼 모델을 통해 추출을 하여 여러 이미지를 받아도 객체 인식이 가능하였다.\n",
    "\n",
    "- 기본 실행 구조\n",
    "    1. 이미지 입력\n",
    "    2. 모델을 사용하여 입력받은 이미지에서 식재료 객체 추출\n",
    "    3. 탐지에 실패하거나 신뢰도가 낮다고 판단하면 openai 이미지 분석을 통해 재추출 진행\n",
    "    4. 추출된 식재료들을 단일 리스트 형태로 반환\n",
    "\n",
    "### 아쉬운점 & 개선할 부분\n",
    "- 컴퓨터의 용량 문제로 YOLO 모델 학습을 진행할 때 충분한 데이터셋을 사용하지 못하여 충분히 성능을 끌어올리지 못했다. 이번 학습에서는 4~5천여장의 사진으로 30가지의 클래스를 학습시켜야 했기 때문에 실사용은 어려울 수 있고, YOLO를 사용해본 것에 의의를 두었다고 생각한다. 만약 다음 기회가 있다면, AI-Hub의 데이터셋을 이용하여 충분한 학습을 통하여 openai의 보조 없이도 높은 성능을 보여줄 수 있는 YOLO 모델을 학습시켜보고 싶다. \n",
    "\n",
    "- 여러 개의 이미지 데이터셋을 모아 새롭게 라벨링을 하여 더 큰 규모의 데이터셋을 만들어 학습을 진행하고자 하였지만, 마찬가지로 컴퓨터에 10만장 이상의 데이터를 저장할 수 없어 실행하지 못하였다. \n",
    "\n",
    "- 더 많은 이미지를 통해 학습을 시킨 모델을 이용하면 더 높은 성능을 기대할 수 있을 것이다. 또한, 여러 메서드를 사용하는데 이 메서드들을 좀 더 다듬어 훨씬 깔끔하고 안정적인 코드 작성이 가능할 것이다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3520dc1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
